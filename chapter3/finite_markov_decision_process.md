### 第三章

### 有限马尔科夫决策过程

​        在本章中，我们将介绍我们在本书其余部分中尝试解决的问题。这个问题可以被认为定义强化学习的领域：任何适合于解决这个问题的方法，我们认为是强化学习方法。

​        在这章我们的目标是在广义上来描述强化学习。我们试图传达可能被用作强化学习任务的各种可能的应用程序。我们还描述了可以进行精确的理论陈述的强化学习问题的理想化数学形式。我们介绍该问题的数学结构的关键部分，例如价值函数和贝尔曼方程。在所有的人工智能中，在适用性的宽度和数学易处理性之间存在矛盾（a tension）。在本章中，我们将介绍这种矛盾，并讨论一些它所带来的权衡和挑战。

####         3.1智能体环境接口

​          强化学习问题意味着从交互学习到实现目标的问题的直接框架。智能体在其中进行学习和决策。除了智能体本身，智能体与之交互的一切，称之为环境。它们不断地交互，智能体选择动作同时环境响应那些动作并向智能体呈现新的情况[^1]	，智能体试图随着时间最大化环境所反馈的奖励数值。一个完整规范的环境，包括如何确定奖励，定义一个强化学习问题的实例作为任务。

[^1]: 我们使用术语智能体，环境和动作，而不是工程师术语控制器，受控系统（或工厂）和控制信号，因为它们对更广泛的受众有意义。

